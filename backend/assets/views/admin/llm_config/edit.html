<!-- Edit LLM Config Modal -->
<div class="fixed inset-0 z-[60] bg-black/50">
    <div class="fixed inset-y-0 right-0 w-full max-w-2xl bg-background shadow-xl overflow-hidden flex flex-col">
        <!-- Header -->
        <div class="flex items-center justify-between px-6 py-4 border-b">
            <h2 class="text-lg font-semibold">Edit LLM Configuration</h2>
            <button onclick="document.getElementById('modal-container').innerHTML = ''"
                class="inline-flex items-center justify-center rounded-md h-8 w-8 hover:bg-accent">
                <svg class="h-4 w-4" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor">
                    <path stroke-linecap="round" stroke-linejoin="round" d="M6 18L18 6M6 6l12 12" />
                </svg>
            </button>
        </div>

        <!-- Form -->
        <form hx-patch="/admin/llm-configs/{{ item.id }}" hx-ext="json-enc"
              hx-target="#llm-config-row-{{ item.id }}" hx-swap="outerHTML"
              hx-on::after-request="if(event.detail.successful && event.detail.elt === this) document.getElementById('modal-container').innerHTML = ''"
              class="flex-1 overflow-y-auto p-6">
            <div class="space-y-6">
                <!-- Name -->
                <div class="space-y-2">
                    <label for="name" class="text-sm font-medium">Name</label>
                    <input type="text" id="name" name="name" value="{{ item.name }}" required
                        class="flex h-9 w-full rounded-md border border-input bg-background px-3 py-1 text-sm shadow-sm
                               placeholder:text-muted-foreground focus-visible:outline-none focus-visible:ring-1 focus-visible:ring-ring"
                        placeholder="e.g., Production Ollama Server" />
                </div>

                <!-- Provider -->
                <div class="space-y-2">
                    <label for="provider" class="text-sm font-medium">Provider</label>
                    <select id="provider" name="provider" required
                        onchange="toggleLocalLlmFields()"
                        class="flex h-9 w-full rounded-md border border-input bg-background px-3 py-1 text-sm shadow-sm
                               focus-visible:outline-none focus-visible:ring-1 focus-visible:ring-ring">
                        <option value="">Select provider...</option>
                        <optgroup label="On-Premise (Production)">
                            <option value="ollama" {% if item.provider == "ollama" %}selected{% endif %}>Ollama</option>
                            <option value="llama-cpp" {% if item.provider == "llama-cpp" %}selected{% endif %}>llama.cpp Server (HTTP)</option>
                            <option value="local-llama-cpp" {% if item.provider == "local-llama-cpp" %}selected{% endif %}>llama.cpp Native (In-Process)</option>
                            <option value="vllm" {% if item.provider == "vllm" %}selected{% endif %}>vLLM</option>
                        </optgroup>
                        <optgroup label="Remote (Development)">
                            <option value="openai" {% if item.provider == "openai" %}selected{% endif %}>OpenAI Compatible</option>
                            <option value="groq" {% if item.provider == "groq" %}selected{% endif %}>Groq</option>
                            <option value="anthropic" {% if item.provider == "anthropic" %}selected{% endif %}>Anthropic</option>
                        </optgroup>
                    </select>
                    <p class="text-xs text-muted-foreground">
                        For production, use on-premise providers. "llama.cpp Native" runs models in-process without a separate server.
                    </p>
                </div>

                <!-- Endpoint URL (hidden for local-llama-cpp) -->
                <div id="endpoint_url_section" class="space-y-2" {% if item.provider == "local-llama-cpp" %}style="display: none;"{% endif %}>
                    <label for="endpoint_url" class="text-sm font-medium">Endpoint URL</label>
                    <input type="url" id="endpoint_url" name="endpoint_url" value="{{ item.endpoint_url }}"
                        class="flex h-9 w-full rounded-md border border-input bg-background px-3 py-1 text-sm shadow-sm font-mono
                               placeholder:text-muted-foreground focus-visible:outline-none focus-visible:ring-1 focus-visible:ring-ring"
                        placeholder="http://localhost:11434" />
                    <p class="text-xs text-muted-foreground">
                        The LLM server endpoint (e.g., http://localhost:11434 for Ollama).
                    </p>
                </div>

                <!-- Local LLM Settings (only for local-llama-cpp) -->
                <div id="local_llm_section" class="space-y-4 p-4 rounded-lg border bg-blue-50 dark:bg-blue-950" {% if item.provider != "local-llama-cpp" %}style="display: none;"{% endif %}>
                    <h3 class="text-sm font-medium text-blue-700 dark:text-blue-300">Local LLM Settings</h3>

                    <!-- Model Path -->
                    <div class="space-y-2">
                        <label for="model_path" class="text-sm font-medium">Model Path</label>
                        <input type="text" id="model_path" name="model_path" value="{{ item.model_path }}"
                            class="flex h-9 w-full rounded-md border border-input bg-background px-3 py-1 text-sm shadow-sm font-mono
                                   placeholder:text-muted-foreground focus-visible:outline-none focus-visible:ring-1 focus-visible:ring-ring"
                            placeholder="llm-models/your-model.gguf" />
                        <p class="text-xs text-muted-foreground">
                            Path to GGUF model file. Relative paths are from backend directory.
                        </p>
                    </div>

                    <div class="grid grid-cols-2 gap-4">
                        <!-- Context Size -->
                        <div class="space-y-2">
                            <label for="n_ctx" class="text-sm font-medium">Context Size</label>
                            <input type="number" id="n_ctx" name="n_ctx" value="{{ item.n_ctx | default(value=4096) }}" min="512" max="32768"
                                class="flex h-9 w-full rounded-md border border-input bg-background px-3 py-1 text-sm shadow-sm
                                       focus-visible:outline-none focus-visible:ring-1 focus-visible:ring-ring" />
                            <p class="text-xs text-muted-foreground">Context window size</p>
                        </div>

                        <!-- CPU Threads -->
                        <div class="space-y-2">
                            <label for="n_threads" class="text-sm font-medium">CPU Threads</label>
                            <input type="number" id="n_threads" name="n_threads" value="{{ item.n_threads | default(value=4) }}" min="1" max="64"
                                class="flex h-9 w-full rounded-md border border-input bg-background px-3 py-1 text-sm shadow-sm
                                       focus-visible:outline-none focus-visible:ring-1 focus-visible:ring-ring" />
                            <p class="text-xs text-muted-foreground">Number of CPU threads</p>
                        </div>
                    </div>
                </div>

                <script>
                function toggleLocalLlmFields() {
                    const provider = document.getElementById('provider').value;
                    const isLocalLlm = provider === 'local-llama-cpp';

                    document.getElementById('endpoint_url_section').style.display = isLocalLlm ? 'none' : 'block';
                    document.getElementById('local_llm_section').style.display = isLocalLlm ? 'block' : 'none';
                    document.getElementById('model_name_section').style.display = isLocalLlm ? 'none' : 'block';

                    // Make endpoint_url and model_name not required for local-llama-cpp
                    document.getElementById('endpoint_url').required = !isLocalLlm;
                    const modelNameField = document.getElementById('model_name');
                    if (modelNameField) modelNameField.required = !isLocalLlm;
                }
                </script>

                <!-- Model Name (hidden for local-llama-cpp) -->
                <div id="model_name_section" class="space-y-2" {% if item.provider == "local-llama-cpp" %}style="display: none;"{% endif %}>
                    <div class="flex items-center justify-between">
                        <label for="model_name" class="text-sm font-medium">Model Name</label>
                        <button type="button"
                            hx-get="/admin/llm-configs/models"
                            hx-include="[name='endpoint_url']"
                            hx-vals='{"current_model": "{{ item.model_name }}"}'
                            hx-target="#model_name_container"
                            hx-swap="innerHTML"
                            hx-indicator="#model-loading"
                            hx-disinherit="*"
                            class="inline-flex items-center gap-1 text-xs text-muted-foreground hover:text-foreground px-2 py-1 rounded hover:bg-accent">
                            <span id="model-loading" class="htmx-indicator">
                                <svg class="animate-spin h-3 w-3" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24">
                                    <circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle>
                                    <path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path>
                                </svg>
                            </span>
                            <svg class="h-3 w-3" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor">
                                <path stroke-linecap="round" stroke-linejoin="round" d="M16.023 9.348h4.992v-.001M2.985 19.644v-4.992m0 0h4.992m-4.993 0l3.181 3.183a8.25 8.25 0 0013.803-3.7M4.031 9.865a8.25 8.25 0 0113.803-3.7l3.181 3.182m0-4.991v4.99" />
                            </svg>
                            Fetch Models
                        </button>
                    </div>
                    <div id="model_name_container">
                        {% if available_models | length > 0 %}
                        <select id="model_name" name="model_name" {% if item.provider != "local-llama-cpp" %}required{% endif %}
                            class="flex h-9 w-full rounded-md border border-input bg-background px-3 py-1 text-sm shadow-sm font-mono
                                   focus-visible:outline-none focus-visible:ring-1 focus-visible:ring-ring">
                            <option value="">Select model...</option>
                            {% for model in available_models %}
                            <option value="{{ model.name }}" {% if model.name == item.model_name %}selected{% endif %}>{{ model.name }}{% if model.details and model.details.parameter_size %} ({{ model.details.parameter_size }}){% endif %}</option>
                            {% endfor %}
                        </select>
                        <p class="text-xs text-muted-foreground mt-1">
                            Found {{ available_models | length }} model(s). Or type a model name manually below.
                        </p>
                        {% else %}
                        <input type="text" id="model_name" name="model_name" value="{{ item.model_name }}" {% if item.provider != "local-llama-cpp" %}required{% endif %}
                            class="flex h-9 w-full rounded-md border border-input bg-background px-3 py-1 text-sm shadow-sm font-mono
                                   placeholder:text-muted-foreground focus-visible:outline-none focus-visible:ring-1 focus-visible:ring-ring"
                            placeholder="e.g., llama3.1:latest, codellama:13b" />
                        <p class="text-xs text-muted-foreground mt-1">
                            Type model name or click "Fetch Models" after entering the endpoint URL.
                        </p>
                        {% endif %}
                    </div>
                </div>

                <!-- API Key (Optional) -->
                <div class="space-y-2">
                    <label for="api_key" class="text-sm font-medium">API Key (Optional)</label>
                    <input type="password" id="api_key" name="api_key" value="{{ item.api_key }}"
                        class="flex h-9 w-full rounded-md border border-input bg-background px-3 py-1 text-sm shadow-sm font-mono
                               placeholder:text-muted-foreground focus-visible:outline-none focus-visible:ring-1 focus-visible:ring-ring"
                        placeholder="sk-..." />
                    <p class="text-xs text-muted-foreground">
                        API key if required by the provider.
                    </p>
                </div>

                <!-- Generation Parameters -->
                <div class="space-y-4 p-4 rounded-lg border bg-muted/30">
                    <h3 class="text-sm font-medium">Generation Parameters</h3>

                    <div class="grid grid-cols-2 gap-4">
                        <!-- Temperature -->
                        <div class="space-y-2">
                            <label for="temperature" class="text-sm font-medium">Temperature</label>
                            <input type="number" id="temperature" name="temperature" value="{{ item.temperature | default(value=0.7) | round(precision=1) }}" min="0" max="2" step="0.1"
                                class="flex h-9 w-full rounded-md border border-input bg-background px-3 py-1 text-sm shadow-sm
                                       focus-visible:outline-none focus-visible:ring-1 focus-visible:ring-ring" />
                        </div>

                        <!-- Max Tokens -->
                        <div class="space-y-2">
                            <label for="max_tokens" class="text-sm font-medium">Max Tokens</label>
                            <input type="number" id="max_tokens" name="max_tokens" value="{{ item.max_tokens | default(value=4096) }}" min="256" max="32768"
                                class="flex h-9 w-full rounded-md border border-input bg-background px-3 py-1 text-sm shadow-sm
                                       focus-visible:outline-none focus-visible:ring-1 focus-visible:ring-ring" />
                        </div>
                    </div>
                </div>

                <!-- Is Active -->
                <div class="flex items-center space-x-2">
                    <input type="hidden" id="is_active_hidden" name="is_active" value="{% if item.is_active %}true{% else %}false{% endif %}" />
                    <input type="checkbox" id="is_active_checkbox"
                        {% if item.is_active %}checked{% endif %}
                        onchange="document.getElementById('is_active_hidden').value = this.checked ? 'true' : 'false'"
                        class="h-4 w-4 rounded border-input" />
                    <label for="is_active_checkbox" class="text-sm font-medium">Active</label>
                </div>
            </div>
        </form>

        <!-- Footer -->
        <div class="flex items-center justify-end gap-2 px-6 py-4 border-t bg-muted/30">
            <button onclick="document.getElementById('modal-container').innerHTML = ''"
                class="inline-flex items-center justify-center rounded-md text-sm font-medium h-9 px-4 py-2
                       border bg-background shadow-sm hover:bg-accent hover:text-accent-foreground">
                Cancel
            </button>
            <button type="submit"
                onclick="this.closest('.fixed').querySelector('form').requestSubmit()"
                class="inline-flex items-center justify-center rounded-md text-sm font-medium h-9 px-4 py-2
                       bg-primary text-primary-foreground shadow-sm hover:bg-primary/90">
                Save Changes
            </button>
        </div>
    </div>
</div>
