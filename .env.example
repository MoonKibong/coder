# xFrame5 Code Generator - Environment Configuration
#
# Copy this file to .env and update the values for your environment.
# IMPORTANT: Never commit .env to version control.

# ============================================
# Application Settings
# ============================================
APP_PORT=3000
APP_HOST=0.0.0.0
APP_URL=http://localhost:3000
RUST_LOG=info

# ============================================
# Database Configuration
# ============================================
POSTGRES_USER=coder
POSTGRES_PASSWORD=coder_password
POSTGRES_DB=coder_production

# Full database URL (for direct connection)
# DATABASE_URL=postgres://coder:coder_password@localhost:5432/coder_production

# ============================================
# LLM Configuration
# ============================================
# Provider: ollama | llama-cpp | vllm | groq | openai | anthropic
LLM_PROVIDER=ollama

# Model to use (provider-specific)
# Ollama: codellama:13b, codellama:7b, mistral, etc.
# vLLM: codellama/CodeLlama-13b-hf
LLM_MODEL=codellama:13b

# LLM Endpoint (for on-premise providers)
# LLM_ENDPOINT=http://localhost:11434

# Request timeout in seconds
LLM_TIMEOUT=120

# API Key (required for cloud providers: groq, openai, anthropic)
# LLM_API_KEY=your-api-key-here

# ============================================
# Authentication
# ============================================
# IMPORTANT: Change this in production!
JWT_SECRET=your-secure-jwt-secret-here
JWT_EXPIRATION=86400

# ============================================
# CORS Configuration
# ============================================
CORS_ORIGIN=*

# ============================================
# Database Pool Settings
# ============================================
DB_CONNECT_TIMEOUT=5000
DB_IDLE_TIMEOUT=10000
DB_MIN_CONNECTIONS=5
DB_MAX_CONNECTIONS=20
